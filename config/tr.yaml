trainer:
    n_epochs: 50
    total_batch_size: 128
    optimizer: adafactor
    validate_each: 1

    lr_decay:
        type: inverse_sqrt
        peak_learning_rate: 0.5e-3
        finetune_learning_rate: 0.1e-3
        warmup_steps: 4000

    output_callback:
        postprocessing: 
            type: none  # none, alnum, aspell
            bias: 1.0

    delay_finetuning:
        n_steps: 100000

dataset:
    mode: wiki  # baseline, wiki, augmented
    language: tr
    lowercase: false
    batch_size: 8
    threads: 4
    p_corrupted: 0.0
    tokenizer: google/byt5-small
    encoder_max_length: 296
    decoder_max_length: 32

    noise_probs:
        multiplier: 0.9
        typo: 0.01
        missing_vowels: 0.00144118
        remove_repeated: 0.0058027
        repeated_letters: 0.0116436
        remove_accents: 0.3629629

        replaced_apostrophe: 0.08724832

        joined_words: 0.0299549
        split_words: 0.0169175
        split_into_letters: 0.008
        prefix: 0.0161415

        first_upper_to_lower: 0.01022067
        upper_to_lower: 0.016957
        lower_to_first_upper: 0.2154811
        upper_to_first_upper: 0.0167364
        lower_to_upper: 0.4036697
        first_upper_to_upper: 0.05504587

model:
    pretrained_lm: google/byt5-small
    weight_decay: 0.0
    n_beams: 2

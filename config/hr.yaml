trainer:
    n_epochs: 50
    total_batch_size: 128
    optimizer: adafactor
    validate_each: 1

    lr_decay:
        type: inverse_sqrt
        peak_learning_rate: 0.5e-3
        finetune_learning_rate: 0.1e-3
        warmup_steps: 4000

    output_callback:
        postprocessing: none  # none, alnum, aspell

    delay_finetuning:
        n_steps: 100000

dataset:
    mode: wiki  # baseline, wiki, augmented
    language: hr
    lowercase: true
    batch_size: 32
    threads: 4
    p_corrupted: 0.0
    tokenizer: google/byt5-small
    encoder_max_length: 200
    decoder_max_length: 32

    noise_probs:
        multiplier: 0.765856
        typo: 0.006
        missing_vowels: 0.0002
        remove_repeated: 0.0060918
        remove_accents:  0.19375098131

        replaced_hyphen: 0.067864
        replaced_o: 0.018511
        replaced_a: 0.0022376
        replaced_o_a: 0.0148093
        replaced_end_i: 0.053595
        replaced_i: 0.010791

        repeated_letters: 0.002214
        prefix: 0.011285

model:
    pretrained_lm: google/byt5-small
    weight_decay: 0.0
    n_beams: 1
